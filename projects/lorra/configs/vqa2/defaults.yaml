# Use soft copy
dataset_config:
  vqa2:
    zoo_requirements:
    - coco.defaults
    - coco.resnet152
    - vqa2.defaults
    features:
      train:
      - coco/defaults/features/trainval2014.lmdb,coco/resnet152/features/trainval2014.lmdb
      val:
      - coco/defaults/features/trainval2014.lmdb,coco/resnet152/features/trainval2014.lmdb
      test:
      - coco/defaults/features/test2015.lmdb,coco/resnet152/features/test2015.lmdb

    use_ocr: true
    processors:
      context_processor:
        type: fasttext
        params:
          download_initially: true
          max_length: 50
          model_file: wiki.en.bin
      answer_processor:
        type: soft_copy_answer
        params:
          vocab_file: vqa2/defaults/extras/vocabs/answers_vqa.txt
          preprocessor:
            type: simple_word
            params: {}
          context_preprocessor:
            type: simple_word
            params: {}
          max_length: 50
          num_answers: 10

optimizer:
  type: Adamax
  params:
    eps: 1.0e-08
    lr: 0.01
    weight_decay: 0

evaluation:
  metrics:
  - vqa_accuracy

training:
  clip_norm_mode: all
  clip_gradients: true
  lr_ratio: 0.1
  lr_scheduler: true
  lr_steps:
  - 15000
  - 18000
  - 20000
  - 21000
  max_grad_l2_norm: 0.25
  max_updates: 22000
  use_warmup: true
  warmup_factor: 0.2
  warmup_iterations: 1000
  batch_size: 512
  num_workers: 7
  task_size_proportional_sampling: true
  early_stop:
    criteria: vqa2/vqa_accuracy
    minimize: false

checkpoint:
  pretrained_state_mapping:
    text_embeddings: text_embeddings
    context_embeddings: context_embeddings
    image_feature_encoders: image_feature_encoders
    image_feature_embeddings_list: image_feature_embeddings_list
    image_text_multi_modal_combine_layer: image_text_multi_modal_combine_layer

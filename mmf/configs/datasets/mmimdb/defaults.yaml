dataset_config:
  mmimdb:
    data_dir: ${env.data_dir}
    depth_first: false
    fast_read: false
    use_images: true
    use_features: false
    images:
      train:
      - datasets/mmimdb/defaults/images/mmimdb/dataset/
      val:
      - datasets/mmimdb/defaults/images/mmimdb/dataset/
      test:
      - datasets/mmimdb/defaults/images/mmimdb/dataset/
    features:
      train:
      - datasets/mmimdb/defaults/features/features.lmdb
      val:
      - datasets/mmimdb/defaults/features/features.lmdb
      test:
      - datasets/mmimdb/defaults/features/features.lmdb
    annotations:
      train:
      - datasets/mmimdb/defaults/annotations/train.jsonl
      val:
      - datasets/mmimdb/defaults/annotations/dev.jsonl
      test:
      - datasets/mmimdb/defaults/annotations/test.jsonl
    max_features: 100
    processors:
      text_processor:
        type: vocab
        params:
          max_length: 70
          vocab:
            type: intersected
            embedding_name: glove.6B.300d
            vocab_file: datasets/mmimdb/defaults/extras/vocab_mmimdb.txt
          preprocessor:
            type: simple_sentence
            params: {}
      bbox_processor:
        type: bbox
        params:
          max_length: 50
      answer_processor:
        type: multi_hot_answer_from_vocab
        params:
            num_answers: 1
            vocab_file: datasets/mmimdb/defaults/extras/classes_mm_imdb.txt
            preprocessor:
                type: simple_word
                params: {}
      image_processor:
        type: torchvision_transforms
        params:
          transforms:
            - type: Resize
              params:
                size: [256, 256]
            - type: CenterCrop
              params:
                size: [224, 224]
            - ToTensor
            - GrayScaleTo3Channels
            - type: Normalize
              params:
                mean: [0.46777044, 0.44531429, 0.40661017]
                std: [0.12221994, 0.12145835, 0.14380469]
    return_features_info: false

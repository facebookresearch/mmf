model_config:
  mmbt_rag:    
    training_head_type: pretraining
    bert_model_name: bert-base-uncased
    direct_features_input: false
    freeze_text: false
    freeze_modal: false
    freeze_complete_base: false
    finetune_lr_multiplier: 1
    # Dimension of the embedding finally returned by the modal encoder
    modal_hidden_size: 2048
    # Dimension of the embedding finally returned by the text encoder
    text_hidden_size: 768
    # Used when classification head is activated
    num_labels: 2
    modal_encoder:
      type: resnet152
      params:
        pretrained: true
        pool_type: avg
        num_output_features: 1
    use_modal_start_token: true
    use_modal_end_token: true
    text_encoder:
      type: transformer
      params:
        num_segments: 2
        bert_model_name: ${model_config.mmbt_rag.bert_model_name}
        hidden_size: 768
        num_hidden_layers: 12
        num_attention_heads: 12
        output_attentions: false
        output_hidden_states: false
